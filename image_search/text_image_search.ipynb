{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using text to search images\n",
    "We will use three options and compare results:\n",
    "- Azure Computer Vision embeddings - single vector works for both image and text based search, very easy to use\n",
    "- Azure Computer Vision captions with OpenAI embeddings (single caption for whole image)\n",
    "- Azure Computer Vision dense captions with OpenAI embeddings (concatenation of all captions for objects for whole image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os\n",
    "import pandas as pd\n",
    "import random\n",
    "from PIL import Image\n",
    "from matplotlib import pyplot as plt\n",
    "import cv2\n",
    "from dotenv import load_dotenv\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configurations\n",
    "target_folder = \"val2017\"\n",
    "source_folder = \"test2017\"\n",
    "top_n = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Azure Computer Vision embeddings\n",
    "azurecv_embeddings = pd.read_parquet(\"azurecv_image_embeddings.parquet\")\n",
    "\n",
    "# Load OpenAI embeddings of captions and dense captions\n",
    "openai_captions_embeddings = pd.read_parquet(\"azurecv_image_captions_openai_embeddings.parquet\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
