{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading and processing data with Lang Chain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create data loader using Git. This will clone whole Azure Docs repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import GitLoader\n",
    "\n",
    "# Data loader - documentation on GitHub, filter only markdown files\n",
    "loader = GitLoader(\n",
    "    clone_url=\"https://github.com/MicrosoftDocs/azure-docs\",\n",
    "    repo_path=\"./data/\",\n",
    "    file_filter=lambda file_path: file_path.endswith(\".md\"),\n",
    ")\n",
    "\n",
    "\n",
    "data = loader.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how many files are downloaded and what they are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded 10 files\n",
      "----------------------------\n",
      "README.md\n",
      "demo_kube\\README.md\n",
      "docs\\compute_isolation.md\n",
      "docs\\deployment.md\n",
      "docs\\network_isolation.md\n",
      "docs\\policies.md\n",
      "docs\\storage_isolation.md\n",
      "docs\\terraform.md\n",
      "modules\\aks-apps-rbac\\docs\\terraform.md\n",
      "modules\\aks-system\\docs\\terraform.md\n"
     ]
    }
   ],
   "source": [
    "print(f\"Downloaded {len(data)} files\")\n",
    "print(\"----------------------------\")\n",
    "for file in data:\n",
    "    print(file.metadata[\"file_path\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will configure text splitter to split large md files into smaller chunks.\n",
    "\n",
    "Note: Lang Chain supports context aware splitting of Markdown, which would be great for very big files. Issue is I do not want to make chunks too small (this might destroy context) and Azure Docs are having single file per page. Some might be small enough so it is not worth splitting them by chapters. Big ones might, but then even chapter needs to be split into smaller one (or 3rd grade chapter like ### will need to be used rendering too many too small chunks overall)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size = 500, chunk_overlap = 25)\n",
    "all_splits = text_splitter.split_documents(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many chunks we have got?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "113"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_splits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see some chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(page_content='- For single source of truth provide YAML manifest with all cluster parameters (shared components, namespaces, applications) that will be consumed by both Azure resources deployment (Terraform) and Kubernetes resources deployment (ArgoCD).\\r\\n- Each application will use its own namespace that is network isolated from others and only communication allowed is via Ingress or Azure API Management self-hosted gateway.', metadata={'source': 'README.md', 'file_path': 'README.md', 'file_name': 'README.md', 'file_type': '.md'})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_splits[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Configure URL and API key for Azure OpenAI service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%env BASE_URL = https://tom-canada-openai.openai.azure.com\n",
    "%env API_KEY = mykey"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get embeddings for chunks and store it in FAISS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "import os\n",
    "\n",
    "embedding = OpenAIEmbeddings(\n",
    "    openai_api_base=os.environ[\"BASE_URL\"],\n",
    "    openai_api_key=os.environ[\"API_KEY\"],\n",
    "    openai_api_type=\"azure\",\n",
    "    openai_api_version=\"2023-05-15\",\n",
    "    deployment=\"text-embedding-ada-002\",\n",
    "    model=\"text-embedding-ada-002\",\n",
    "    chunk_size=16)   # Note chunk_size here is misleading - it is more like batch size, how many should be send to API at once\n",
    "\n",
    "vectorstore = FAISS.from_documents(documents=all_splits, embedding=embedding)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try some question and similarity search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='## Network architecture and isolation\\r\\n\\r\\n\\r\\n```mermaid\\r\\nflowchart TD\\r\\n    subgraph api_subnet\\r\\n        api_server\\r\\n    end;\\r\\n\\r\\n    api_subnet --> main_subnet\\r\\n    api_subnet --> confidential_app3_subnet\\r\\n    api_subnet --> confidential_app4_subnet\\r\\n\\r\\n    subgraph main_subnet\\r\\n        subgraph standard_app1_namespace\\r\\n            subgraph standard_app1_component1\\r\\n                standard_app1_service1 --> standard_app1_pod1\\r\\n                standard_app1_service1 --> standard_app1_pod2', metadata={'source': 'docs\\\\network_isolation.md', 'file_path': 'docs\\\\network_isolation.md', 'file_name': 'network_isolation.md', 'file_type': '.md'}),\n",
       " Document(page_content='```\\r\\n\\r\\nThis will create example hub and spoke topology with Azure Firewall, Azure VPN and jump server. T. Since solution is using private endpoints your deployment server needs to be in VNET - in demo solution you can use either jump server or connect via P2S VPN.\\r\\n\\r\\nIn **VPN** option download configuration of Azure VPN Client from portal (or configure your own OpenVPN client) a add following to XML configuration to make sure DNS resolving works:\\r\\n\\r\\n```xml\\r\\n  <clientconfig>\\r\\n    <dnsservers>', metadata={'source': 'docs\\\\deployment.md', 'file_path': 'docs\\\\deployment.md', 'file_name': 'deployment.md', 'file_type': '.md'}),\n",
       " Document(page_content='<dnsservers>\\r\\n      <dnsserver>10.80.3.4</dnsserver>\\r\\n    </dnsservers>\\r\\n    <dnssuffixes>\\r\\n      <dnssuffix>.privatelink.northeurope.azmk8s.io</dnssuffix>\\r\\n      <dnssuffix>.northeurope.azmk8s.io</dnssuffix>\\r\\n      <dnssuffix>.privatelink.vaultcore.azure.net</dnssuffix>\\r\\n      <dnssuffix>.vault.azure.net</dnssuffix>\\r\\n    </dnssuffixes>\\r\\n  </clientconfig>\\r\\n```', metadata={'source': 'docs\\\\deployment.md', 'file_path': 'docs\\\\deployment.md', 'file_name': 'deployment.md', 'file_type': '.md'}),\n",
       " Document(page_content='configurations .-> network_policies;\\r\\n        configurations .-> storage_classes;\\r\\n        configurations .-> service_accounts;\\r\\n        configurations .-> resource_quotas;\\r\\n    end;\\r\\n\\r\\n    runtime .-> configurations\\r\\n```\\r\\n\\r\\n## Automation steps\\r\\n```mermaid\\r\\ngraph TD;\\r\\n    tf[Terraform apply] --> install[Install ArgoCD via Azure API command invoke]\\r\\n    tf .-> runtime{runtime.yaml}\\r\\n    manifest{manifest.yaml} .-> tf', metadata={'source': 'README.md', 'file_path': 'README.md', 'file_name': 'README.md', 'file_type': '.md'})]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = \"How is network configured?\"\n",
    "docs = vectorstore.similarity_search(question)\n",
    "docs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is how we will save FAISS to file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorstore.save_local(folder_path=\".\", index_name=\"azuredocs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try loading FAISS from file and do some similarity search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='## Network architecture and isolation\\r\\n\\r\\n\\r\\n```mermaid\\r\\nflowchart TD\\r\\n    subgraph api_subnet\\r\\n        api_server\\r\\n    end;\\r\\n\\r\\n    api_subnet --> main_subnet\\r\\n    api_subnet --> confidential_app3_subnet\\r\\n    api_subnet --> confidential_app4_subnet\\r\\n\\r\\n    subgraph main_subnet\\r\\n        subgraph standard_app1_namespace\\r\\n            subgraph standard_app1_component1\\r\\n                standard_app1_service1 --> standard_app1_pod1\\r\\n                standard_app1_service1 --> standard_app1_pod2', metadata={'source': 'docs\\\\network_isolation.md', 'file_path': 'docs\\\\network_isolation.md', 'file_name': 'network_isolation.md', 'file_type': '.md'}),\n",
       " Document(page_content='```\\r\\n\\r\\nThis will create example hub and spoke topology with Azure Firewall, Azure VPN and jump server. T. Since solution is using private endpoints your deployment server needs to be in VNET - in demo solution you can use either jump server or connect via P2S VPN.\\r\\n\\r\\nIn **VPN** option download configuration of Azure VPN Client from portal (or configure your own OpenVPN client) a add following to XML configuration to make sure DNS resolving works:\\r\\n\\r\\n```xml\\r\\n  <clientconfig>\\r\\n    <dnsservers>', metadata={'source': 'docs\\\\deployment.md', 'file_path': 'docs\\\\deployment.md', 'file_name': 'deployment.md', 'file_type': '.md'}),\n",
       " Document(page_content='<dnsservers>\\r\\n      <dnsserver>10.80.3.4</dnsserver>\\r\\n    </dnsservers>\\r\\n    <dnssuffixes>\\r\\n      <dnssuffix>.privatelink.northeurope.azmk8s.io</dnssuffix>\\r\\n      <dnssuffix>.northeurope.azmk8s.io</dnssuffix>\\r\\n      <dnssuffix>.privatelink.vaultcore.azure.net</dnssuffix>\\r\\n      <dnssuffix>.vault.azure.net</dnssuffix>\\r\\n    </dnssuffixes>\\r\\n  </clientconfig>\\r\\n```', metadata={'source': 'docs\\\\deployment.md', 'file_path': 'docs\\\\deployment.md', 'file_name': 'deployment.md', 'file_type': '.md'}),\n",
       " Document(page_content='configurations .-> network_policies;\\r\\n        configurations .-> storage_classes;\\r\\n        configurations .-> service_accounts;\\r\\n        configurations .-> resource_quotas;\\r\\n    end;\\r\\n\\r\\n    runtime .-> configurations\\r\\n```\\r\\n\\r\\n## Automation steps\\r\\n```mermaid\\r\\ngraph TD;\\r\\n    tf[Terraform apply] --> install[Install ArgoCD via Azure API command invoke]\\r\\n    tf .-> runtime{runtime.yaml}\\r\\n    manifest{manifest.yaml} .-> tf', metadata={'source': 'README.md', 'file_path': 'README.md', 'file_name': 'README.md', 'file_type': '.md'})]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorstore2 = FAISS.load_local(folder_path=\".\", index_name=\"azuredocs\", embeddings=embedding)\n",
    "question = \"How is network configured?\"\n",
    "docs = vectorstore2.similarity_search(question)\n",
    "docs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
