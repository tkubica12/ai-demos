{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare results\n",
    "Let's have the same prompt and see results for different situations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define prompt\n",
    "prompt = \"To configure blob storage account permissions, you need to \"\n",
    "\n",
    "import subprocess\n",
    "from IPython.display import Markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('azure_docs_out/ckpt.pt', <http.client.HTTPMessage at 0x7ff01c1c6230>)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Download my checkpoint files if you have not done training yourself\n",
    "\n",
    "import urllib.request\n",
    "import os\n",
    "\n",
    "if not os.path.exists(\"azure_docs_out\"):\n",
    "    os.makedirs(\"azure_docs_out\")\n",
    "azure_docs_out_url = \"https://tkubicastore.blob.core.windows.net/checkpoints/azure_docs_out/ckpt.pt?sp=r&st=2023-09-08T16:41:31Z&se=2055-09-09T00:41:31Z&spr=https&sv=2022-11-02&sr=b&sig=ExYW%2FWFuRp75%2FF4CpTml5E2XZiuHssZHMJxX%2FJvJ8Os%3D\"\n",
    "urllib.request.urlretrieve(azure_docs_out_url, \"azure_docs_out/ckpt.pt\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GPT2 124M with downloaded weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmd = f\"/bin/python3 sample.py --init_from=gpt2 --num_samples=5 --max_new_tokens=300 --start='{prompt}'\"\n",
    "output = subprocess.check_output(cmd, shell=True).decode(\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overriding: init_from = gpt2\n",
      "Overriding: num_samples = 5\n",
      "Overriding: max_new_tokens = 300\n",
      "Overriding: start = To configure blob storage account permissions, you need to \n",
      "loading weights from pretrained gpt: gpt2\n",
      "forcing vocab_size=50257, block_size=1024, bias=True\n",
      "overriding dropout rate to 0.0\n",
      "number of parameters: 123.65M\n",
      "No meta.pkl found, assuming GPT-2 encodings...\n",
      "To configure blob storage account permissions, you need to  list the configuration files that will have the permissions for the blob storage account that you want to give it permission to access.  I found this to be easier than I had ever been.\n",
      "I have the following files for the configuration files:\n",
      "<USER>/Library/Application Support/Microsoft Windows/Installer/Microsoft Office 2012/Installer.exe <USER>\\Library/Application Support/Microsoft Windows Store\\Installer\\Installer.exe <USER>\\Library/Application Support/Microsoft Office 2011\\Installer\\Installer.exe <USER>\\Library/Application Support/Microsoft Office 2012\\Installer\\Installer.exe <USER>\\Library/Application Support/Windows Store\\Installer\\Installer.exe\n",
      "To access the blob storage account file, you have to go to the file that contains the settings, and then click on the File button.\n",
      "Then, hit the Save button.  Sign in, and go to the file that contains the settings you just signed in with.\n",
      "Repeat this until you see the file that was created as the admin password.\n",
      "You should now have access to the admin string, which you will need to update.  Set the following settings in the settings folder in the\n",
      "\\Installer\\Desktop\\Folder\\Binder\\<|endoftext|>According to a new study, the majority of American adults have never seen heroin or cocaine, and most have not even heard of drugs other than cocaine.\n",
      "\n",
      "---------------\n",
      "To configure blob storage account permissions, you need to  change the default values of the storage account and the account password. If no other credentials are set, use the following commands:\n",
      "curl -X POST -X DELETE -d '{\"username\":\"$USERNAME\"}'.format( 'CRIMINAL_ID' ) # add the password to this account with the first email address curl -D \"MyAccountName\" -d '{\"username\":\"$USERNAME\",\"password\":\"$PASSWORD\"}' | awk -F '{print $1}'; # create a temporary storage account for the DB and store it in the account database curl -D \"MyAccountName\" -d \"{\"username\":\"$USERNAME\",\"password\":\"$PASSWORD\"}' | awk -F '{print $2}'; # create a new storage account for the DB and store it in the account database curl -D 'MyAccountName\" -d \"{\"username\":\"$USERNAME\",\"password\":\"$PASSWORD\"}' | awk -F '{print $3}';\n",
      "Now we can disable the storage account completely by adding this line to the config file:\n",
      "curl -d '{https:\"user@yourdomain.com\"}'.format( 'SYSTEM_ADDRESS', '\\\"yourdomain.com\\\"');\n",
      "Finally, we can disable the network connection just by changing the default values of the network settings. To enable the default network settings,\n",
      "---------------\n",
      "To configure blob storage account permissions, you need to  configure the  accounts on the web server. This will help reduce disk space and allow you to keep any files that have been deleted. Once you have this permission, just enter the  name of the file and press enter. You will be prompted to fill out the form. You should see the file listed in the \"File\" section. This command sets the permissions of the files in your attachment, the one that contains your public key and the one that contains your private key.\n",
      "# Create Blob Storage Account and Set it to a Namespace And Password\n",
      "Create a new file named \"image_factory_settings.sql\" in the  directory of your  Windows Server 2013 (or Windows Server 2016) installation.  This file is the namespaces associated with the IIS images in the image storage namespace.\n",
      "# Create Blob Storage Account for Windows Server 2013 and Windows Server 2012\n",
      "# Create Blob Storage Account in Word, Excel and PowerPoint\n",
      "# Create Blob Storage Account in Office 2012\n",
      "Create a new file named \"image_factory_settings.sql\" in the  directory of your  Windows Server 2013 (or Windows Server 2016) installation.  This file is the namespaces associated with the IIS images in the image storage namespace.  Please see the next screenshot below.  You can note that the value of the  name of the file is the  name of the blob storage account.  \n",
      "---------------\n",
      "To configure blob storage account permissions, you need to  use the following configuration option.\n",
      "-h  This indicates the registry key is hidden from it's own operations. \n",
      "-i  This changes the value of the registry key . The default value is \"KEYWORDS\" and the value is the entire registry key.\n",
      "-c  This changes the value of the registry key . The default value is \"SECRET\" and the value is \"AUTO,\n",
      "`\".\n",
      "-u  This changes the value of the registry key . The default value is \"IDLE\" and the value is the entire registry key.\n",
      "-c  This changes the value of the registry key . The default value is \"LOCAL_KEY\" and the value is the entire registry key.\n",
      "-v  This changes the value of the registry key . The default value is \"VS_SECRET\" and the value is the entire registry key.\n",
      "-h  This changes the value of the registry key . The default value is \"HKLM\\SOFTWARE\\Microsoft\\Windows NT\\CurrentVersion\\Explorer\\Microsoft.Windows.PreventRoot.aspx\" and the value is the entire registry key.\n",
      "-i  This changes the value of the registry key . The default value is \"DEFAULT\" and the value is the entire registry key.\n",
      "-c  This changes the value of the registry key . The default value is \"USER=ALL\" and the value\n",
      "---------------\n",
      "To configure blob storage account permissions, you need to idsize the entire Blockchain, etc.\n",
      "\n",
      "# # You need to take care to not screw up your batch database entry. In the case of an index query, you like to set the batch db full at version 1.6.6 or later.\n",
      "\n",
      "[CmdletBinding()#add @{`setenv svc5`} ]\n",
      "\n",
      "let value = [{id: 0, name: \"sha256\", value: value)}\n",
      "\n",
      "let get = [{username: \"john\", password: \"john\", status: \"OK\" }]\n",
      "\n",
      "let key = {attributes: \"success\", value:\"Hello, world\".}\n",
      "\n",
      "let get = [{attributes: \"error\", value:\"Hello, world\".})\n",
      "\n",
      "let key = [{attributes: \"hidden\", value:\"\".}];\n",
      "\n",
      "Now, let's be careful. You can't just count the number of buckets. You need to have the entries get exactly the number of bucket at the top, etc. And be careful not to get too much work from (or damage) the existing structure.\n",
      "\n",
      "In any event, this is a very simple example and I can't really help you with it. Make sure you follow the exact instructions for use.\n",
      "\n",
      "After you've created a Bucket type, you can check that you have successfully created the bucket.\n",
      "\n",
      "let bucket = [{createdId: 0, name: \"my_\n",
      "---------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GPT2 124M trained from scratch using our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmd = f\"/bin/python3 sample.py --out_dir=azure_docs_out --num_samples=5 --max_new_tokens=300 --start='{prompt}'\"\n",
    "output = subprocess.check_output(cmd, shell=True).decode(\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Overriding: out_dir = azure_docs_out\n",
       "Overriding: num_samples = 5\n",
       "Overriding: max_new_tokens = 300\n",
       "Overriding: start = To configure blob storage account permissions, you need to \n",
       "number of parameters: 123.59M\n",
       "No meta.pkl found, assuming GPT-2 encodings...\n",
       "To configure blob storage account permissions, you need to  blob storage account configuration settings.\n",
       "\n",
       "The following sections describe how to define the blob indexer connection string. Depending on the context of your data connector has, you can use `DefaultStorageAccountSasToken`.\n",
       "\n",
       "### Blob storage access signature\n",
       "The blob indexer requires an Azure Storage account to retrieve a blob from Blob storage. Blob storage is an Azure resource that doesn't use blob storage as a storage account with a blob access policy. The following command creates a Blob storage container and uploads a blob to it:\n",
       "\n",
       "```azurecli\n",
       "az storage blob create -i <storage-account-name> -s <container-name> --account-name <storage-account-key>\n",
       "```\n",
       "\n",
       "To access blob data in the same virtual machine, the storage account must be granted access to a resource, such as a blob or a group.\n",
       "\n",
       "## Read data\n",
       "\n",
       "The blob indexer requires a read-only access signature. The blob indexer requires a read-only access signature. The key is of one of the following formats:\n",
       "\n",
       "| Format | Format | Default | Notes |\n",
       "|--------|----------------|-------|--------------|\n",
       "| `<storage-account-name>` |`{`blob`*`| String | The blob name to read data from the storage account. Valid characters are `{` and `}` when using the blob name. Only valid characters are allowed\n",
       "---------------\n",
       "To configure blob storage account permissions, you need to  [Blob Data Contributor](built-in-roles.md#storage-account-contributor) role.\n",
       "\n",
       "The following example creates a storage account and passes the access key permissions to the storage account.\n",
       "\n",
       "```csharp\n",
       "private static DataLakeStorageAccountRolePermission.StorageAccount;\n",
       "private static DataLakeStorageAccount authorization;\n",
       "private static DataLakeStorageAccount authorization;\n",
       "private static DataLakeStorageAccount authorization;\n",
       "private static DataLakeStorageAccount authorization;\n",
       "private static DataLakeStoreAccount authorization;\n",
       "private static DataLakeStoreAccount authorization;\n",
       "private static DataLakeStoreSharedAccess;\n",
       "private static DataLakeStoreLakeStoreAccount authorization;\n",
       "private static DataLakeStoreSharedAccessSignature, FileAccessControl;\n",
       "private static DataLakeStoreAccount authorization;\n",
       "private static DataLakeStoreSharedAccessSignature.Uri = DataStoreSharedAccessSignature(\n",
       "     (string, string, string, string)\n",
       "     .> None);\n",
       "    string ACL = false;\n",
       "    string dataLakeStoreName = \"atalakestore\"\n",
       "      .ToString(dataLakeStoreName, DataLakeStoreAccountName, FileSecurityPolicy applied.DefaultName, defaultPermission,\n",
       "               \n",
       "              \n",
       "---------------\n",
       "To configure blob storage account permissions, you need to  Blob Data Contributor role on the storage account that contains the permission to perform the operations. For more information, see [Permissions for Blob Data Contributor](built-in-roles.md#permissions-for-blob-data-contributor).\n",
       "\n",
       "### Blobfuse.datafactory\n",
       "\n",
       "This section contains the general steps to set up data movement in Blobfuse.\n",
       "\n",
       "1. A blobfuse storage account.\n",
       "1. A blobfuse storage account.\n",
       "1. A blobfuse storage account.\n",
       "1. A blobfuse datafactory default storage account.\n",
       "1. A blobfuse storage account.\n",
       "1. A blobfuse storage account.\n",
       "1. A blobfuse storage account.\n",
       "1. A blobfuse namespace.\n",
       "1. A blobfuse storage account.\n",
       "1. An event hub consumer event hub.\n",
       "1. A blobfuse event hub consumer event hub consumer logon\n",
       "\n",
       "The blobfuse consumer logon log on this container:\n",
       "\n",
       "When a blobfuse event hub and blobfuse is deleted (except for Azure Stream Analytics, Azure Stream Analytics, or Azure Storage), then the block blobfuse container is deleted.\n",
       "\n",
       "See [`blobfuse.txt`](#blobfuse.txt) for blobfuse to read how to persist blobfuse to back up the containers.\n",
       "\n",
       "---------------\n",
       "To configure blob storage account permissions, you need to \n",
       "\n",
       "The following diagram shows how to create a storage account and then access data.\n",
       "\n",
       ":::image type=\"content\" source=\"media/blob-backup/create-route-storage-account-scope.png\" alt-text=\"Screenshot showing how to create a storage account.\":::\n",
       "\n",
       "The storage account must be placed into a comma-separated value (CSV) or CER format (CSV). To retrieve this information, copy the contents of the file. For example, the file name is **AzureBackupDataShare**.\n",
       "\n",
       "The following example shows how to create a storage account with the following settings:\n",
       "\n",
       "```json\n",
       "{\n",
       "   \"storageAccountConfiguration\": {\n",
       "     \"StorageAccountType\": \"Standard_LRS\",\n",
       "     \"Locale\": \"Enabled\"\n",
       "   },\n",
       "   \"StorageAccountType\": \"Standard\"\n",
       "}\n",
       "```\n",
       "\n",
       "The following example shows how to create a storage account with the following settings:\n",
       "\n",
       "```json\n",
       "{\n",
       "   \"storageAccountDCA\": {\n",
       "     \"storageAccountType\": \"Standard\"\n",
       "   },\n",
       "   \"location\": {\n",
       "     \"type\": \"string\",\n",
       "     \"defaultValue\": \"eastus\",\n",
       "     \"metadata\": {\n",
       "       \"description\":\n",
       "---------------\n",
       "To configure blob storage account permissions, you need to blob container. To learn how to use Azure Storage Explorer, see [File Blob overview](storage-explorer.md).\n",
       "\n",
       "### Delete a blob\n",
       "\n",
       "You can manage all of your Storage resources by using the [Azure portal](https://portal.azure.com), [Storage Explorer](https://storageexplorer.com/) or [Power BI](https://powerbi.microsoft.com/documentation/azure-storage-explorer/) to manage the resources you need.\n",
       "\n",
       "Azure Storage Explorer is available in Azure Storage Explorer. You can get:\n",
       "\n",
       "- Create a storage account and blob container.\n",
       "- Verify that all blobs that are older than a storage account.\n",
       "- Delete a storage account.\n",
       "- Delete a storage account.\n",
       "\n",
       "## Next steps\n",
       "\n",
       "- Learn more about [Azure Storage Explorer](https://storageexplorer.com).\n",
       "- Learn more about [Azure Storage Explorer](https://storageexplorer.com).\n",
       "---\n",
       "title: Azure storage containers and resources\n",
       "description: Azure storage services (LFS) are used to lock, bind, and delete storage accounts on a Virtual Machine (VM) to a storage account in Azure Storage.\n",
       "services: storage\n",
       "author: normesta\n",
       "\n",
       "ms.service: storage\n",
       "ms.topic: conceptual\n",
       "ms.date: 08/18/2022\n",
       "ms.author: normesta\n",
       "\n",
       "---\n",
       "# Azure storage management\n",
       "---------------\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Markdown(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GPT2 124M finetuned with out data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GPT2 124M with downloaded weights + in-context learning\n",
    "Suppose we have way to search for data outside of our model based on query from prompt and add this document into our prompt for in-context learning. I have different demo on this using GPT4 and embeddings so for know let just assume:\n",
    "1. We can download Azure documentation repository and each chapter (markdown file) we can run embeddings on or store it in some classic full-text search system.\n",
    "2. We get our prompt and create embeddings and use vector similatiry search to find most similar document in our \"external memory\" or use this prompt as query in standard full-text search engine and get most relevant document.\n",
    "3. We will place content of this document into our prompt. For purpose of this demo we will skip all searching and just use relevant_context.md file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"context/blob-containers-cli.md\", \"r\") as f:\n",
    "    enhanced_prompt = f.read().replace(\"'\", \"\").replace('\"', \"\").replace(\"=\", \"\")\n",
    "enhanced_prompt = enhanced_prompt + \"\\n\\n\\n\\n\" + prompt\n",
    "\n",
    "cmd = f\"/bin/python3 sample.py --init_from=gpt2 --num_samples=1 --max_new_tokens=1000 --start='{enhanced_prompt}'\"\n",
    "output = subprocess.check_output(cmd, shell=True).decode(\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Overriding: init_from = gpt2\n",
       "Overriding: num_samples = 1\n",
       "Overriding: max_new_tokens = 1000\n",
       "Overriding: start = ---\n",
       "title: Manage blob containers using Azure CLI\n",
       "titleSuffix: Azure Storage\n",
       "description: Learn how to manage Azure storage containers using Azure CLI\n",
       "services: storage\n",
       "author: stevenmatthew\n",
       "\n",
       "ms.service: azure-storage\n",
       "ms.topic: how-to\n",
       "ms.date: 02/05/2022\n",
       "ms.author: shaas\n",
       "ms.devlang: azurecli\n",
       "ms.custom: devx-track-azurecli\n",
       "---\n",
       "\n",
       "# Manage blob containers using Azure CLI\n",
       "\n",
       "Microsoft Azure Blob Storage allows you to store large amounts of unstructured object data. You can use blob storage to gather or expose media, content, or application data to users. Because all blob data is stored within containers, you must create a storage container before you can begin to upload data. To learn more about blob storage, read the [Introduction to Azure Blob storage](storage-blobs-introduction.md).\n",
       "\n",
       "The Azure CLI is Azures cross-platform command-line experience for managing Azure resources. You can use it in your browser with Azure Cloud Shell. You can also install it on macOS, Linux, or Windows and run it locally from the command line.\n",
       "\n",
       "In this how-to article, you learn to use the Azure CLI with Bash to work with container objects.\n",
       "\n",
       "## Prerequisites\n",
       "\n",
       "[!INCLUDE [storage-quickstart-prereq-include](../../../includes/storage-quickstart-prereq-include.md)]\n",
       "\n",
       "[!INCLUDE [azure-cli-prepare-your-environment.md](~/articles/reusable-content/azure-cli/azure-cli-prepare-your-environment-h3.md)]\n",
       "\n",
       "- Its always a good idea to install the latest version of the Azure CLI. If using Azure Cloud Shell, the latest version is already installed.\n",
       "\n",
       "### Authorize access to Blob storage\n",
       "\n",
       "You can authorize access to Blob storage from the Azure CLI either with Azure AD credentials or by using the storage account access key. Using Azure AD credentials is recommended, and this articles examples use Azure AD exclusively.\n",
       "\n",
       "Azure CLI commands for data operations against Blob storage support the `--auth-mode` parameter, which enables you to specify how to authorize a given operation. Set the `--auth-mode` parameter to `login` to authorize with Azure AD credentials. For more information, see [Authorize access to blob or queue data with Azure CLI](./authorize-data-operations-cli.md?toc/azure/storage/blobs/toc.json).\n",
       "\n",
       "Run the `login` command to open a browser and connect to your Azure subscription.\n",
       "\n",
       "```azurecli-interactive\n",
       "az login\n",
       "```\n",
       "\n",
       "## Create a container\n",
       "\n",
       "To create a container with Azure CLI, call the [az storage container create](/cli/azure/storage/container#az-storage-container-create) command.The following example illustrates three options for the creation of blob containers with the `az storage container create` command. The first approach creates a single container, while the remaining two approaches use Bash scripting operations to automate container creation.\n",
       "\n",
       "To use this example, supply values for the variables and ensure that youve logged in. Remember to replace the placeholder values in brackets with your own values.\n",
       "\n",
       "```azurecli\n",
       "#!/bin/bash\n",
       "storageAccount<storage-account>\n",
       "containerNamedemo-container-1\n",
       "containerPrefixdemo-container-\n",
       "\n",
       "# Approach 1: Create a container\n",
       "az storage container create \\\n",
       "    --name $containerName \\\n",
       "    --account-name $storageAccount \\\n",
       "    --auth-mode login\n",
       "\n",
       "# Approach 2: Create containers with a loop\n",
       "for value in {2..5}\n",
       "do\n",
       "    az storage container create \\\n",
       "        --name $containerPrefix$value \\\n",
       "        --account-name $storageAccount \\\n",
       "        --auth-mode login\n",
       "done\n",
       "\n",
       "# Approach 3: Create containers by splitting multiple values\n",
       "containerList${containerPrefix}6 ${containerPrefix}7 ${containerPrefix}8\n",
       "for container in $containerList\n",
       "do\n",
       "    az storage container create \\\n",
       "        --name $container \\\n",
       "        --account-name $storageAccount \\\n",
       "        --auth-mode login\n",
       "done\n",
       "```\n",
       "\n",
       "## List containers\n",
       "\n",
       "Use the `az storage container list` command to retrieve a list of storage containers. To return a list of containers whose names begin with a given character string, pass the string as the `--prefix` parameter value.\n",
       "\n",
       "The `--num-results` parameter can be used to limit the number of containers returned by the request. Azure Storage limits the number of containers returned by a single listing operation to 5000. This limit ensures that manageable amounts of data are retrieved. If the number of containers returned exceeds either the `--num-results` value or the service limit, a continuation token is returned. This token allows you to use multiple requests to retrieve any number of containers.\n",
       "\n",
       "You can also use the `--query` parameter to execute a [JMESPath query](/cli/azure/query-azure-cli) on the results of commands. JMESPath is a query language for JSON that allows you to select and modify data returned from CLI output. Queries are executed on the JSON output before it can be formatted. For more information, see [How to query Azure CLI command output using a JMESPath query](/cli/azure/query-azure-cli).\n",
       "\n",
       "The following example first lists the maximum number of containers (subject to the service limit). Next, it lists three containers whose names begin with the prefix *container-* by supplying values for the `--num-results` and `--prefix` parameters. Finally, a single container is listed by supplying a known container name to the `--prefix` parameter.\n",
       "\n",
       "Read more about the [az storage container list](/cli/azure/storage/container#az-storage-container-list).\n",
       "\n",
       "```azurecli-interactive\n",
       "#!/bin/bash\n",
       "storageAccount<storage-account>\n",
       "containerPrefixdemo-container-\n",
       "containerNamedemo-container-1\n",
       "numResults3\n",
       "\n",
       "# Approach 1: List maximum containers\n",
       "az storage container list \\\n",
       "    --account-name $storageAccount \\\n",
       "    --auth-mode login\n",
       "\n",
       "# Approach 2: List a defined number of named containers\n",
       "az storage container list \\\n",
       "    --prefix $containerPrefix \\\n",
       "    --num-results $numResults \\\n",
       "    --account-name $storageAccount \\\n",
       "    --auth-mode login\n",
       "\n",
       "# Approach 3: List an individual container\n",
       "az storage container list \\\n",
       "    --prefix $containerPrefix \\\n",
       "    --query [?name$containerName] \\\n",
       "    --account-name $storageAccount \\\n",
       "    --auth-mode login\n",
       "```\n",
       "\n",
       "## Read container properties and metadata\n",
       "\n",
       "A container exposes both system properties and user-defined metadata. System properties exist on each blob storage resource. Some properties are read-only, while others can be read or set. Under the covers, some system properties map to certain standard HTTP headers.\n",
       "\n",
       "User-defined metadata consists of one or more name-value pairs that you specify for a blob storage resource. You can use metadata to store additional values with the resource. Metadata values are for your own purposes only, and dont affect how the resource behaves.\n",
       "\n",
       "### Container properties\n",
       "\n",
       "To display the properties of a container with Azure CLI, call the [az storage container show](/cli/azure/storage/container#az-storage-container-show) command.\n",
       "\n",
       "In the following example, the first approach displays the properties of a single named container. Afterward, it retrieves all containers with the **demo-container-** prefix and iterates through them, listing their properties. Remember to replace the placeholder values with your own values.\n",
       "\n",
       "```azurecli-interactive\n",
       "#!/bin/bash\n",
       "storageAccount<storage-account>\n",
       "containerPrefixdemo-container-\n",
       "containerNamedemo-container-1\n",
       "\n",
       "# Show a named containers properties\n",
       "az storage container show \\\n",
       "    --name $containerName \\\n",
       "    --account-name $storageAccount \\\n",
       "    --auth-mode login\n",
       "\n",
       "# List several containers and show their properties\n",
       "containerList$(az storage container list \\\n",
       "    --query [].name \\\n",
       "    --prefix $containerPrefix \\\n",
       "    --account-name $storageAccount \\\n",
       "    --auth-mode login \\\n",
       "    --output tsv)\n",
       "\n",
       "for row in $containerList\n",
       "do\n",
       "  tmpRow$(echo $row | sed -e s/\\r//g)\n",
       "  az storage container show --name $tmpRow --account-name $storageAccount --auth-mode login\n",
       "done\n",
       "```\n",
       "\n",
       "### Read and write container metadata\n",
       "\n",
       "Users that have many thousands of objects within their storage account can quickly locate specific containers based on their metadata. To read the metadata, youll use the `az storage container metadata show` command. To update metadata, youll need to call the `az storage container metadata update` command. The method only accepts space-separated key-value pairs. For more information, see the [az storage container metadata](/cli/azure/storage/container/metadata) documentation.\n",
       "\n",
       "The first example below updates and then retrieves a named containers metadata. The second example iterates the list of containers matching the `-prefix` value. Containers with names containing even numbers have their metadata set with values contained in the *metadata* variable.\n",
       "\n",
       "```azurecli-interactive\n",
       "#!/bin/bash\n",
       "storageAccount<storage-account>\n",
       "containerNamedemo-container-1\n",
       "containerPrefixdemo-container-\n",
       "\n",
       "# Create metadata string\n",
       "metadatakeyvalue piedelicious\n",
       "\n",
       "# Update named container metadata\n",
       "az storage container metadata update \\\n",
       "    --name $containerName \\\n",
       "    --metadata $metadata \\\n",
       "    --account-name $storageAccount \\\n",
       "    --auth-mode login\n",
       "\n",
       "# Display metadata\n",
       "az storage container metadata show \\\n",
       "    --name $containerName \\\n",
       "    --account-name $storageAccount \\\n",
       "    --auth-mode login\n",
       "\n",
       "# Get list of containers\n",
       "containerList$(az storage container list \\\n",
       "    --query [].name \\\n",
       "    --prefix $containerPrefix \\\n",
       "    --account-name $storageAccount \\\n",
       "    --auth-mode login \\\n",
       "    --output tsv)\n",
       "\n",
       "# Update and display metadata\n",
       "for row in $containerList\n",
       "do\n",
       "  #Get the containers number\n",
       "  tmpName$(echo $row | sed -e s/\\r//g)\n",
       "  if [ `expr ${tmpName: ${#containerPrefix}} % 2`  0 ]\n",
       "  then\n",
       "    az storage container metadata update \\\n",
       "        --name $tmpName \\\n",
       "        --metadata $metadata \\\n",
       "        --account-name $storageAccount \\\n",
       "        --auth-mode login\n",
       "    \n",
       "    echo $tmpName\n",
       "\n",
       "    az storage container metadata show \\\n",
       "    --name $tmpName \\\n",
       "    --account-name $storageAccount \\\n",
       "    --auth-mode login    \n",
       "  fi\n",
       "done\n",
       "```\n",
       "\n",
       "## Delete containers\n",
       "\n",
       "Depending on your use case, you can delete a single container or a group of containers with the `az storage container delete` command. When deleting a list of containers, youll need to use conditional operations as shown in the examples below.\n",
       "\n",
       "> [!WARNING]\n",
       "> Running the following examples may permanently delete containers and blobs. Microsoft recommends enabling container soft delete to protect containers and blobs from accidental deletion. For more info, see [Soft delete for containers](soft-delete-container-overview.md).\n",
       "\n",
       "```azurecli-interactive\n",
       "#!/bin/bash\n",
       "storageAccount<storage-account>\n",
       "containerNamedemo-container-1\n",
       "containerPrefixdemo-container-\n",
       "\n",
       "# Delete a single named container\n",
       "az storage container delete \\\n",
       "    --name $containerName \\\n",
       "    --account-name $storageAccount \\\n",
       "    --auth-mode login\n",
       "\n",
       "# Delete containers by iterating a loop\n",
       "list$(az storage container list \\\n",
       "    --query [].name \\\n",
       "    --prefix $containerPrefix \\\n",
       "    --account-name $storageAccount \\\n",
       "    --auth-mode login \\\n",
       "    --output tsv)\n",
       "for row in $list\n",
       "do\n",
       "    tmpName$(echo $row | sed -e s/\\r//g)\n",
       "    az storage container delete \\\n",
       "    --name $tmpName \\\n",
       "    --account-name $storageAccount \\\n",
       "    --auth-mode login\n",
       "done\n",
       "```\n",
       "\n",
       "If you have container soft delete enabled for your storage account, then its possible to retrieve containers that have been deleted. If your storage accounts soft delete data protection option is enabled, the `--include-deleted` parameter will return containers deleted within the associated retention period. The `--include-deleted` parameter can only be used to return containers when used with the `--prefix` parameter. To learn more about soft delete, refer to the [Soft delete for containers](soft-delete-container-overview.md) article.\n",
       "\n",
       "Use the following example to retrieve a list of containers deleted within the storage accounts associated retention period.\n",
       "\n",
       "```azurecli-interactive\n",
       "#!/bin/bash\n",
       "storageAccount<storage-account>\n",
       "containerPrefixdemo-container-\n",
       "\n",
       "# Retrieve a list of containers including those recently deleted\n",
       "az storage container list \\\n",
       "    --prefix $containerPrefix \\\n",
       "    --include-deleted \\\n",
       "    --account-name $storageAccount\\\n",
       "    --auth-mode login\n",
       "```\n",
       "\n",
       "## Restore a soft-deleted container\n",
       "\n",
       "As mentioned in the [List containers](#list-containers) section, you can configure the soft delete data protection option on your storage account. When enabled, its possible to restore containers deleted within the associated retention period. Before you can follow this example, youll need to enable soft delete and configure it on at least one of your storage accounts.\n",
       "\n",
       "The following examples explain how to restore a soft-deleted container with the `az storage container restore` command. Youll need to supply values for the `--name` and `--version` parameters to ensure that the correct version of the container is restored. If you dont know the version number, you can use the `az storage container list` command to retrieve it as shown in the first example. The second example finds and restores all deleted containers within a specific storage account.\n",
       "\n",
       "To learn more about the soft delete data protection option, refer to the [Soft delete for containers](soft-delete-container-overview.md) article.\n",
       "\n",
       "```azurecli-interactive\n",
       "#!/bin/bash\n",
       "storageAccount<storage-account>\n",
       "containerNamedemo-container-1\n",
       "\n",
       "# Restore an individual named container\n",
       "containerVersion$(az storage container list \\\n",
       "    --account-name $storageAccount \\\n",
       "    --query [?name$containerName].[version] \\\n",
       "    --auth-mode login \\\n",
       "    --output tsv \\\n",
       "    --include-deleted | sed -e s/\\r//g)\n",
       "\n",
       "az storage container restore \\\n",
       "    --name $containerName \\\n",
       "    --deleted-version $containerVersion \\\n",
       "    --account-name $storageAccount \\\n",
       "    --auth-mode login\n",
       "\n",
       "# Restore a list of deleted containers\n",
       "containerList$(az storage container list \\\n",
       "    --account-name $storageAccount \\\n",
       "    --include-deleted \\\n",
       "    --auth-mode login \\\n",
       "    --query [?deleted].{name:name,version:version} \\\n",
       "    -o json)\n",
       "\n",
       "for row in $(echo ${containerList} | jq -c .[] )\n",
       "do\n",
       "    tmpName$(echo $row | jq -r .name)\n",
       "    tmpVersion$(echo $row | jq -r .version)\n",
       "    az storage container restore \\\n",
       "        --account-name $storageAccount \\\n",
       "        --name $tmpName \\\n",
       "        --deleted-version $tmpVersion \\\n",
       "        --auth-mode login\n",
       "done\n",
       "```\n",
       "\n",
       "## Get a shared access signature for a container\n",
       "\n",
       "A shared access signature (SAS) provides delegated access to Azure resources. A SAS gives you granular control over how a client can access your data. For example, you can specify which resources are available to the client. You can also limit the types of operations that the client can perform, and specify the interval over which the SAS is valid.\n",
       "\n",
       "A SAS is commonly used to provide temporary and secure access to a client who wouldnt normally have permissions. To generate either a service or account SAS, youll need to supply values for the `–-account-name` and `-–account-key` parameters. An example of this scenario would be a service that allows users read and write their own data to your storage account.\n",
       "\n",
       "Azure Storage supports three types of shared access signatures: user delegation, service, and account SAS. For more information on shared access signatures, see the [Grant limited access to Azure Storage resources using shared access signatures](../common/storage-sas-overview.md) article.\n",
       "\n",
       "> [!CAUTION]\n",
       "> Any client that possesses a valid SAS can access data in your storage account as permitted by that SAS. Its important to protect a SAS from malicious or unintended use. Use discretion in distributing a SAS, and have a plan in place for revoking a compromised SAS.\n",
       "\n",
       "The following example illustrates the process of configuring a service SAS for a specific container using the `az storage container generate-sas` command. Because its generating a service SAS, the example first retrieves the storage account key to pass as the `--account-key` value.\n",
       "\n",
       "The example will configure the SAS with start and expiry times and a protocol. It will also specify the **delete**, **read**, **write**, and **list** permissions in the SAS using the `--permissions` parameter. You can reference the full table of permissions in the [Create a service SAS](/rest/api/storageservices/create-service-sas) article.\n",
       "\n",
       "Copy and paste the Blob SAS token value in a secure location. It will only be displayed once and can’t be retrieved once Bash is closed. To construct the SAS URL, append the SAS token (URI) to the URL for the storage service.\n",
       "\n",
       "```azurecli-interactive\n",
       "#!/bin/bash\n",
       "storageAccount<storage-account>\n",
       "containerNamedemo-container-1\n",
       "permissionsdrwl\n",
       "expiry`date -u -d 30 minutes +%Y-%m-%dT%H:%MZ`\n",
       "\n",
       "accountKey$(az storage account keys list \\\n",
       "    --account-name $storageAccount \\\n",
       "    --query [?permissions  FULL].[value] \\\n",
       "    --output tsv)\n",
       "\n",
       "accountKey$( echo $accountKey | cut -d  -f1 )\n",
       " \n",
       "az storage container generate-sas \\\n",
       "    --name $containerName \\\n",
       "    --https-only \\\n",
       "    --permissions dlrw \\\n",
       "    --expiry $expiry \\\n",
       "    --account-key $accountKey \\\n",
       "    --account-name $storageAccount\n",
       "```\n",
       "\n",
       "> [!NOTE]\n",
       "> The SAS token returned by the Azure CLI does not include the delimiter character (?) for the URL query string. If you are appending the SAS token to a resource URL, remember to append the delimiter character to the resource URL before appending the SAS token.\n",
       "\n",
       "## Next steps\n",
       "\n",
       "In this how-to article, you learned how to manage containers in Blob Storage. To learn more about working with blob storage by using Azure CLI, select an option below.\n",
       "\n",
       "> [!div classnextstepaction]\n",
       "> [Manage block blobs with Azure CLI](blob-cli.md)\n",
       "\n",
       "> [!div classnextstepaction]\n",
       "> [Azure CLI samples for Blob storage](storage-samples-blobs-cli.md?toc/azure/storage/blobs/toc.json)\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "To configure blob storage account permissions, you need to \n",
       "loading weights from pretrained gpt: gpt2\n",
       "forcing vocab_size=50257, block_size=1024, bias=True\n",
       "overriding dropout rate to 0.0\n",
       "number of parameters: 123.65M\n",
       "No meta.pkl found, assuming GPT-2 encodings...\n",
       "---\n",
       "title: Manage blob containers using Azure CLI\n",
       "titleSuffix: Azure Storage\n",
       "description: Learn how to manage Azure storage containers using Azure CLI\n",
       "services: storage\n",
       "author: stevenmatthew\n",
       "\n",
       "ms.service: azure-storage\n",
       "ms.topic: how-to\n",
       "ms.date: 02/05/2022\n",
       "ms.author: shaas\n",
       "ms.devlang: azurecli\n",
       "ms.custom: devx-track-azurecli\n",
       "---\n",
       "\n",
       "# Manage blob containers using Azure CLI\n",
       "\n",
       "Microsoft Azure Blob Storage allows you to store large amounts of unstructured object data. You can use blob storage to gather or expose media, content, or application data to users. Because all blob data is stored within containers, you must create a storage container before you can begin to upload data. To learn more about blob storage, read the [Introduction to Azure Blob storage](storage-blobs-introduction.md).\n",
       "\n",
       "The Azure CLI is Azures cross-platform command-line experience for managing Azure resources. You can use it in your browser with Azure Cloud Shell. You can also install it on macOS, Linux, or Windows and run it locally from the command line.\n",
       "\n",
       "In this how-to article, you learn to use the Azure CLI with Bash to work with container objects.\n",
       "\n",
       "## Prerequisites\n",
       "\n",
       "[!INCLUDE [storage-quickstart-prereq-include](../../../includes/storage-quickstart-prereq-include.md)]\n",
       "\n",
       "[!INCLUDE [azure-cli-prepare-your-environment.md](~/articles/reusable-content/azure-cli/azure-cli-prepare-your-environment-h3.md)]\n",
       "\n",
       "- Its always a good idea to install the latest version of the Azure CLI. If using Azure Cloud Shell, the latest version is already installed.\n",
       "\n",
       "### Authorize access to Blob storage\n",
       "\n",
       "You can authorize access to Blob storage from the Azure CLI either with Azure AD credentials or by using the storage account access key. Using Azure AD credentials is recommended, and this articles examples use Azure AD exclusively.\n",
       "\n",
       "Azure CLI commands for data operations against Blob storage support the `--auth-mode` parameter, which enables you to specify how to authorize a given operation. Set the `--auth-mode` parameter to `login` to authorize with Azure AD credentials. For more information, see [Authorize access to blob or queue data with Azure CLI](./authorize-data-operations-cli.md?toc/azure/storage/blobs/toc.json).\n",
       "\n",
       "Run the `login` command to open a browser and connect to your Azure subscription.\n",
       "\n",
       "```azurecli-interactive\n",
       "az login\n",
       "```\n",
       "\n",
       "## Create a container\n",
       "\n",
       "To create a container with Azure CLI, call the [az storage container create](/cli/azure/storage/container#az-storage-container-create) command.The following example illustrates three options for the creation of blob containers with the `az storage container create` command. The first approach creates a single container, while the remaining two approaches use Bash scripting operations to automate container creation.\n",
       "\n",
       "To use this example, supply values for the variables and ensure that youve logged in. Remember to replace the placeholder values in brackets with your own values.\n",
       "\n",
       "```azurecli\n",
       "#!/bin/bash\n",
       "storageAccount<storage-account>\n",
       "containerNamedemo-container-1\n",
       "containerPrefixdemo-container-\n",
       "\n",
       "# Approach 1: Create a container\n",
       "az storage container create \\\n",
       "    --name $containerName \\\n",
       "    --account-name $storageAccount \\\n",
       "    --auth-mode login\n",
       "\n",
       "# Approach 2: Create containers with a loop\n",
       "for value in {2..5}\n",
       "do\n",
       "    az storage container create \\\n",
       "        --name $containerPrefix$value \\\n",
       "        --account-name $storageAccount \\\n",
       "        --auth-mode login\n",
       "done\n",
       "\n",
       "# Approach 3: Create containers by splitting multiple values\n",
       "containerList${containerPrefix}6 ${containerPrefix}7 ${containerPrefix}8\n",
       "for container in $containerList\n",
       "do\n",
       "    az storage container create \\\n",
       "        --name $container \\\n",
       "        --account-name $storageAccount \\\n",
       "        --auth-mode login\n",
       "done\n",
       "```\n",
       "\n",
       "## List containers\n",
       "\n",
       "Use the `az storage container list` command to retrieve a list of storage containers. To return a list of containers whose names begin with a given character string, pass the string as the `--prefix` parameter value.\n",
       "\n",
       "The `--num-results` parameter can be used to limit the number of containers returned by the request. Azure Storage limits the number of containers returned by a single listing operation to 5000. This limit ensures that manageable amounts of data are retrieved. If the number of containers returned exceeds either the `--num-results` value or the service limit, a continuation token is returned. This token allows you to use multiple requests to retrieve any number of containers.\n",
       "\n",
       "You can also use the `--query` parameter to execute a [JMESPath query](/cli/azure/query-azure-cli) on the results of commands. JMESPath is a query language for JSON that allows you to select and modify data returned from CLI output. Queries are executed on the JSON output before it can be formatted. For more information, see [How to query Azure CLI command output using a JMESPath query](/cli/azure/query-azure-cli).\n",
       "\n",
       "The following example first lists the maximum number of containers (subject to the service limit). Next, it lists three containers whose names begin with the prefix *container-* by supplying values for the `--num-results` and `--prefix` parameters. Finally, a single container is listed by supplying a known container name to the `--prefix` parameter.\n",
       "\n",
       "Read more about the [az storage container list](/cli/azure/storage/container#az-storage-container-list).\n",
       "\n",
       "```azurecli-interactive\n",
       "#!/bin/bash\n",
       "storageAccount<storage-account>\n",
       "containerPrefixdemo-container-\n",
       "containerNamedemo-container-1\n",
       "numResults3\n",
       "\n",
       "# Approach 1: List maximum containers\n",
       "az storage container list \\\n",
       "    --account-name $storageAccount \\\n",
       "    --auth-mode login\n",
       "\n",
       "# Approach 2: List a defined number of named containers\n",
       "az storage container list \\\n",
       "    --prefix $containerPrefix \\\n",
       "    --num-results $numResults \\\n",
       "    --account-name $storageAccount \\\n",
       "    --auth-mode login\n",
       "\n",
       "# Approach 3: List an individual container\n",
       "az storage container list \\\n",
       "    --prefix $containerPrefix \\\n",
       "    --query [?name$containerName] \\\n",
       "    --account-name $storageAccount \\\n",
       "    --auth-mode login\n",
       "```\n",
       "\n",
       "## Read container properties and metadata\n",
       "\n",
       "A container exposes both system properties and user-defined metadata. System properties exist on each blob storage resource. Some properties are read-only, while others can be read or set. Under the covers, some system properties map to certain standard HTTP headers.\n",
       "\n",
       "User-defined metadata consists of one or more name-value pairs that you specify for a blob storage resource. You can use metadata to store additional values with the resource. Metadata values are for your own purposes only, and dont affect how the resource behaves.\n",
       "\n",
       "### Container properties\n",
       "\n",
       "To display the properties of a container with Azure CLI, call the [az storage container show](/cli/azure/storage/container#az-storage-container-show) command.\n",
       "\n",
       "In the following example, the first approach displays the properties of a single named container. Afterward, it retrieves all containers with the **demo-container-** prefix and iterates through them, listing their properties. Remember to replace the placeholder values with your own values.\n",
       "\n",
       "```azurecli-interactive\n",
       "#!/bin/bash\n",
       "storageAccount<storage-account>\n",
       "containerPrefixdemo-container-\n",
       "containerNamedemo-container-1\n",
       "\n",
       "# Show a named containers properties\n",
       "az storage container show \\\n",
       "    --name $containerName \\\n",
       "    --account-name $storageAccount \\\n",
       "    --auth-mode login\n",
       "\n",
       "# List several containers and show their properties\n",
       "containerList$(az storage container list \\\n",
       "    --query [].name \\\n",
       "    --prefix $containerPrefix \\\n",
       "    --account-name $storageAccount \\\n",
       "    --auth-mode login \\\n",
       "    --output tsv)\n",
       "\n",
       "for row in $containerList\n",
       "do\n",
       "  tmpRow$(echo $row | sed -e s/\\r//g)\n",
       "  az storage container show --name $tmpRow --account-name $storageAccount --auth-mode login\n",
       "done\n",
       "```\n",
       "\n",
       "### Read and write container metadata\n",
       "\n",
       "Users that have many thousands of objects within their storage account can quickly locate specific containers based on their metadata. To read the metadata, youll use the `az storage container metadata show` command. To update metadata, youll need to call the `az storage container metadata update` command. The method only accepts space-separated key-value pairs. For more information, see the [az storage container metadata](/cli/azure/storage/container/metadata) documentation.\n",
       "\n",
       "The first example below updates and then retrieves a named containers metadata. The second example iterates the list of containers matching the `-prefix` value. Containers with names containing even numbers have their metadata set with values contained in the *metadata* variable.\n",
       "\n",
       "```azurecli-interactive\n",
       "#!/bin/bash\n",
       "storageAccount<storage-account>\n",
       "containerNamedemo-container-1\n",
       "containerPrefixdemo-container-\n",
       "\n",
       "# Create metadata string\n",
       "metadatakeyvalue piedelicious\n",
       "\n",
       "# Update named container metadata\n",
       "az storage container metadata update \\\n",
       "    --name $containerName \\\n",
       "    --metadata $metadata \\\n",
       "    --account-name $storageAccount \\\n",
       "    --auth-mode login\n",
       "\n",
       "# Display metadata\n",
       "az storage container metadata show \\\n",
       "    --name $containerName \\\n",
       "    --account-name $storageAccount \\\n",
       "    --auth-mode login\n",
       "\n",
       "# Get list of containers\n",
       "containerList$(az storage container list \\\n",
       "    --query [].name \\\n",
       "    --prefix $containerPrefix \\\n",
       "    --account-name $storageAccount \\\n",
       "    --auth-mode login \\\n",
       "    --output tsv)\n",
       "\n",
       "# Update and display metadata\n",
       "for row in $containerList\n",
       "do\n",
       "  #Get the containers number\n",
       "  tmpName$(echo $row | sed -e s/\\r//g)\n",
       "  if [ `expr ${tmpName: ${#containerPrefix}} % 2`  0 ]\n",
       "  then\n",
       "    az storage container metadata update \\\n",
       "        --name $tmpName \\\n",
       "        --metadata $metadata \\\n",
       "        --account-name $storageAccount \\\n",
       "        --auth-mode login\n",
       "    \n",
       "    echo $tmpName\n",
       "\n",
       "    az storage container metadata show \\\n",
       "    --name $tmpName \\\n",
       "    --account-name $storageAccount \\\n",
       "    --auth-mode login    \n",
       "  fi\n",
       "done\n",
       "```\n",
       "\n",
       "## Delete containers\n",
       "\n",
       "Depending on your use case, you can delete a single container or a group of containers with the `az storage container delete` command. When deleting a list of containers, youll need to use conditional operations as shown in the examples below.\n",
       "\n",
       "> [!WARNING]\n",
       "> Running the following examples may permanently delete containers and blobs. Microsoft recommends enabling container soft delete to protect containers and blobs from accidental deletion. For more info, see [Soft delete for containers](soft-delete-container-overview.md).\n",
       "\n",
       "```azurecli-interactive\n",
       "#!/bin/bash\n",
       "storageAccount<storage-account>\n",
       "containerNamedemo-container-1\n",
       "containerPrefixdemo-container-\n",
       "\n",
       "# Delete a single named container\n",
       "az storage container delete \\\n",
       "    --name $containerName \\\n",
       "    --account-name $storageAccount \\\n",
       "    --auth-mode login\n",
       "\n",
       "# Delete containers by iterating a loop\n",
       "list$(az storage container list \\\n",
       "    --query [].name \\\n",
       "    --prefix $containerPrefix \\\n",
       "    --account-name $storageAccount \\\n",
       "    --auth-mode login \\\n",
       "    --output tsv)\n",
       "for row in $list\n",
       "do\n",
       "    tmpName$(echo $row | sed -e s/\\r//g)\n",
       "    az storage container delete \\\n",
       "    --name $tmpName \\\n",
       "    --account-name $storageAccount \\\n",
       "    --auth-mode login\n",
       "done\n",
       "```\n",
       "\n",
       "If you have container soft delete enabled for your storage account, then its possible to retrieve containers that have been deleted. If your storage accounts soft delete data protection option is enabled, the `--include-deleted` parameter will return containers deleted within the associated retention period. The `--include-deleted` parameter can only be used to return containers when used with the `--prefix` parameter. To learn more about soft delete, refer to the [Soft delete for containers](soft-delete-container-overview.md) article.\n",
       "\n",
       "Use the following example to retrieve a list of containers deleted within the storage accounts associated retention period.\n",
       "\n",
       "```azurecli-interactive\n",
       "#!/bin/bash\n",
       "storageAccount<storage-account>\n",
       "containerPrefixdemo-container-\n",
       "\n",
       "# Retrieve a list of containers including those recently deleted\n",
       "az storage container list \\\n",
       "    --prefix $containerPrefix \\\n",
       "    --include-deleted \\\n",
       "    --account-name $storageAccount\\\n",
       "    --auth-mode login\n",
       "```\n",
       "\n",
       "## Restore a soft-deleted container\n",
       "\n",
       "As mentioned in the [List containers](#list-containers) section, you can configure the soft delete data protection option on your storage account. When enabled, its possible to restore containers deleted within the associated retention period. Before you can follow this example, youll need to enable soft delete and configure it on at least one of your storage accounts.\n",
       "\n",
       "The following examples explain how to restore a soft-deleted container with the `az storage container restore` command. Youll need to supply values for the `--name` and `--version` parameters to ensure that the correct version of the container is restored. If you dont know the version number, you can use the `az storage container list` command to retrieve it as shown in the first example. The second example finds and restores all deleted containers within a specific storage account.\n",
       "\n",
       "To learn more about the soft delete data protection option, refer to the [Soft delete for containers](soft-delete-container-overview.md) article.\n",
       "\n",
       "```azurecli-interactive\n",
       "#!/bin/bash\n",
       "storageAccount<storage-account>\n",
       "containerNamedemo-container-1\n",
       "\n",
       "# Restore an individual named container\n",
       "containerVersion$(az storage container list \\\n",
       "    --account-name $storageAccount \\\n",
       "    --query [?name$containerName].[version] \\\n",
       "    --auth-mode login \\\n",
       "    --output tsv \\\n",
       "    --include-deleted | sed -e s/\\r//g)\n",
       "\n",
       "az storage container restore \\\n",
       "    --name $containerName \\\n",
       "    --deleted-version $containerVersion \\\n",
       "    --account-name $storageAccount \\\n",
       "    --auth-mode login\n",
       "\n",
       "# Restore a list of deleted containers\n",
       "containerList$(az storage container list \\\n",
       "    --account-name $storageAccount \\\n",
       "    --include-deleted \\\n",
       "    --auth-mode login \\\n",
       "    --query [?deleted].{name:name,version:version} \\\n",
       "    -o json)\n",
       "\n",
       "for row in $(echo ${containerList} | jq -c .[] )\n",
       "do\n",
       "    tmpName$(echo $row | jq -r .name)\n",
       "    tmpVersion$(echo $row | jq -r .version)\n",
       "    az storage container restore \\\n",
       "        --account-name $storageAccount \\\n",
       "        --name $tmpName \\\n",
       "        --deleted-version $tmpVersion \\\n",
       "        --auth-mode login\n",
       "done\n",
       "```\n",
       "\n",
       "## Get a shared access signature for a container\n",
       "\n",
       "A shared access signature (SAS) provides delegated access to Azure resources. A SAS gives you granular control over how a client can access your data. For example, you can specify which resources are available to the client. You can also limit the types of operations that the client can perform, and specify the interval over which the SAS is valid.\n",
       "\n",
       "A SAS is commonly used to provide temporary and secure access to a client who wouldnt normally have permissions. To generate either a service or account SAS, youll need to supply values for the `–-account-name` and `-–account-key` parameters. An example of this scenario would be a service that allows users read and write their own data to your storage account.\n",
       "\n",
       "Azure Storage supports three types of shared access signatures: user delegation, service, and account SAS. For more information on shared access signatures, see the [Grant limited access to Azure Storage resources using shared access signatures](../common/storage-sas-overview.md) article.\n",
       "\n",
       "> [!CAUTION]\n",
       "> Any client that possesses a valid SAS can access data in your storage account as permitted by that SAS. Its important to protect a SAS from malicious or unintended use. Use discretion in distributing a SAS, and have a plan in place for revoking a compromised SAS.\n",
       "\n",
       "The following example illustrates the process of configuring a service SAS for a specific container using the `az storage container generate-sas` command. Because its generating a service SAS, the example first retrieves the storage account key to pass as the `--account-key` value.\n",
       "\n",
       "The example will configure the SAS with start and expiry times and a protocol. It will also specify the **delete**, **read**, **write**, and **list** permissions in the SAS using the `--permissions` parameter. You can reference the full table of permissions in the [Create a service SAS](/rest/api/storageservices/create-service-sas) article.\n",
       "\n",
       "Copy and paste the Blob SAS token value in a secure location. It will only be displayed once and can’t be retrieved once Bash is closed. To construct the SAS URL, append the SAS token (URI) to the URL for the storage service.\n",
       "\n",
       "```azurecli-interactive\n",
       "#!/bin/bash\n",
       "storageAccount<storage-account>\n",
       "containerNamedemo-container-1\n",
       "permissionsdrwl\n",
       "expiry`date -u -d 30 minutes +%Y-%m-%dT%H:%MZ`\n",
       "\n",
       "accountKey$(az storage account keys list \\\n",
       "    --account-name $storageAccount \\\n",
       "    --query [?permissions  FULL].[value] \\\n",
       "    --output tsv)\n",
       "\n",
       "accountKey$( echo $accountKey | cut -d  -f1 )\n",
       " \n",
       "az storage container generate-sas \\\n",
       "    --name $containerName \\\n",
       "    --https-only \\\n",
       "    --permissions dlrw \\\n",
       "    --expiry $expiry \\\n",
       "    --account-key $accountKey \\\n",
       "    --account-name $storageAccount\n",
       "```\n",
       "\n",
       "> [!NOTE]\n",
       "> The SAS token returned by the Azure CLI does not include the delimiter character (?) for the URL query string. If you are appending the SAS token to a resource URL, remember to append the delimiter character to the resource URL before appending the SAS token.\n",
       "\n",
       "## Next steps\n",
       "\n",
       "In this how-to article, you learned how to manage containers in Blob Storage. To learn more about working with blob storage by using Azure CLI, select an option below.\n",
       "\n",
       "> [!div classnextstepaction]\n",
       "> [Manage block blobs with Azure CLI](blob-cli.md)\n",
       "\n",
       "> [!div classnextstepaction]\n",
       "> [Azure CLI samples for Blob storage](storage-samples-blobs-cli.md?toc/azure/storage/blobs/toc.json)\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "To configure blob storage account permissions, you need to **************** * *Make sure that they have the following permissions so that Azure CLI can observe them. * * *For example, if you want data permissions to be set on a blob container, but permission values can't be set globally, visit the BlobStorage permissions option in the Blob Storage account options page.\n",
       "\n",
       "You could also create database accounts to configure Blob Storage authentication or create a user account that reads permissions.\n",
       "\n",
       "Azure CLI pulls your blob storage management account into Blob Storage. You can optionally specify a blank storage account's authorization keys to validate. To configure Vault-a-Burn , you must specify a blank storage account's application password and **************** * *add the access to the BLOB collection account account_id to the array of access_id fields.\n",
       "\n",
       "For more information, see the Azure CLI section on storing containers, see [Your Blob Storage Settings (Accounts)] section.<|endoftext|>A man who lived in a north Edmonton neighbourhood for more than 10 years says he's finally got the courage to fight back against police brutality and murder.\n",
       "\n",
       "\n",
       "Caleb Brieu was just 18 at the time of the shooting last May in Wilfridon, a community of more than 3,000 residents in northeast Edmonton.\n",
       "\n",
       "The 45-year-old woman was sitting in his car at a car wash on the day of the shooting, walking to a friend's house when he heard shots.\n",
       "\n",
       "\n",
       "\"It was about 4:30 a.m. in the morning, the officer was shooting at me and I was just running,\" Caleb told CBC News Friday.\n",
       "\n",
       "\"I was screaming. I thought, 'What the hell is that doing?'\"\n",
       "\n",
       "Brieu told CBC News the shooting had awakened his conscience.\n",
       "\n",
       "\"I told the officer, 'What did you just say?'\" he said.\n",
       "\n",
       "The woman refused to give his name.\n",
       "\n",
       "\"I was scared. I had to defend myself. I was in shock, really nervous,\" he said.\n",
       "\n",
       "\"I told the officer, 'You… you know how they try to scare people? You never really think about warning people, you just… you just can't do it.' You can't stop it.\"\n",
       "\n",
       "\n",
       "He says police have told him the city of Wilfridon will ask Crown to investigate the incident.\n",
       "\n",
       "\"I'm not giving up on anybody,\" he said.\n",
       "\n",
       "According to the police report, a male suspect who was seen at the scene was later identified as Craig Lyle.\n",
       "\n",
       "\n",
       "He said he was driving westbound on Calton Street when he saw the officer.\n",
       "\n",
       "\"There was a car on the side and [the officer] said 'I'm going to shoot you.' He was in the car,\" he said.\n",
       "\n",
       "\"I was just running, I was screaming and I was just afraid of what that guy could do.\"\n",
       "\n",
       "\n",
       "When police arrived, the woman was taken to the hospital.\n",
       "\n",
       "Brieu says the woman was taken to hospital by ambulance.\n",
       "\n",
       "\"She's fine, she's just really shaken,\" he said.\n",
       "\n",
       "Police say the man was detained by members of the public who brought him to hospital.\n",
       "\n",
       "\n",
       "\"It's not out of the ordinary for a police officer to be in a relationship with an individual when that's going on and they're out there [to arrest] them,\" his lawyer, Richard Lyle, said.\n",
       "\n",
       "\n",
       "\"I'm just really bummed that it didn't happen.\"\n",
       "\n",
       "\n",
       "Officers confirm that they are investigating the shooting.\n",
       "\n",
       "\"We're reviewing all aspects of this case,\" said Const. Marc Chienot.\n",
       "\n",
       "He says his client should get his right to court and face justice.\n",
       "\n",
       "\n",
       "Follow @cbcgroup<|endoftext|>\"The words 'toss there, and you shall find' have been used as a metaphor for the future, and so are those that echo the words of an ageing and dying man.\" – Richard Wright\n",
       "\n",
       "There are three problems with the term 'toss there' today:\n",
       "\n",
       "The words are used to describe a place where the people who live there are unable to grasp the underlying history that is moving them there. This does not invalidate the people who live there and who experience pain and suffering in how they move forward with their lives. It does not invalidate the people living here who live here who are unable to understand the underlying history that is moving them there.\n",
       "\n",
       "There are two possible periods under which 'toss there' can occur:\n",
       "\n",
       "Rise of the proletariat at the end of the 19th century (since 1920s)\n",
       "\n",
       "\n",
       "Revolt of the bourgeoisie in the 19th century (since 1950s)\n",
       "\n",
       "\n",
       "The second problem comes from Bob Thors,\n",
       "\n",
       "The German author of the famous essay 'Toss\n",
       "---------------\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Markdown(output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
